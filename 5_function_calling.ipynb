{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dntfreitas/introduction-agents-ai/blob/main/5_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8607462cd18ffe94"
      },
      "cell_type": "markdown",
      "source": [
        "### Function Calling in OpenAI\n",
        "\n",
        "OpenAI's **function calling** feature allows language models like GPT-4 to interact with external tools, APIs, or Python functions in a structured and predictable way. This is particularly useful when you want the model to trigger specific actions, retrieve up-to-date data, or follow a controlled workflow.\n",
        "\n",
        "#### What is Function Calling?\n",
        "\n",
        "Instead of producing free-form text, the model can be instructed to return structured data that matches the signature of a predefined function. The model can \"decide\" to call one of these functions and generate the appropriate arguments, allowing developers to safely and reliably integrate AI into complex applications.\n",
        "\n",
        "#### How It Works\n",
        "\n",
        "1. **Define a function schema**: You provide the model with the name, description, and parameters of the function using a JSON schema.\n",
        "2. **Send a prompt and functions to the model**: Along with the user's message, you send the list of function definitions.\n",
        "3. **Model responds with a function call**: If appropriate, the model will return the name of the function and the arguments it believes should be used.\n",
        "4. **Execute the function in your environment**: Your code runs the function using the provided arguments.\n",
        "5. **Optionally send the result back to the model**: The output of the function can be fed back into the model for further reasoning or response generation."
      ],
      "id": "8607462cd18ffe94"
    },
    {
      "metadata": {
        "id": "c6a0b908e38bbc7b"
      },
      "cell_type": "code",
      "source": [
        "# Let's make sure we have the required libraries installed for this tutorial.\n",
        "!pip install openai dateparser gradio requests PyPDF2"
      ],
      "id": "c6a0b908e38bbc7b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cac9d652034ddc79"
      },
      "cell_type": "code",
      "source": [
        "# Now, let's import the necessary libraries and set up our environment.\n",
        "\n",
        "import json\n",
        "\n",
        "import dateparser\n",
        "import gradio as gr\n",
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "from openai import OpenAI\n"
      ],
      "id": "cac9d652034ddc79",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "70bf14abb0b2c5e"
      },
      "cell_type": "code",
      "source": [
        "# As we are going to use Google Coolab, we don't need to load the environment variables.\n",
        "# Otherwise, you can use the following code to load the environment variables from a `.env` file.\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv(override=True)\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "id": "70bf14abb0b2c5e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "388027c91b229d7d"
      },
      "cell_type": "code",
      "source": [
        "# Now, let's initialize the OpenAI API client.\n",
        "openai = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "id": "388027c91b229d7d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "e1d6c6689907fccf"
      },
      "cell_type": "code",
      "source": [
        "# Load and Extract Madeira PDF Content\n",
        "# This is an easier, less efficient, RAG method.\n",
        "\n",
        "reader = PdfReader(\"docs/Madeira.pdf\")\n",
        "pdf_text = \"\"\n",
        "\n",
        "for page in reader.pages:\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        pdf_text += text"
      ],
      "id": "e1d6c6689907fccf",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "fc05bc62ff4bf63"
      },
      "cell_type": "code",
      "source": [
        "# Create the System Prompt\n",
        "# The prompt defines the role of the assistant: a knowledgeable and professional tourist guide.\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are acting as a tourist guide in Madeira. You are answering questions on a website, \"\n",
        "    \"about the island of Madeira, particularly questions related to the island's history, culture, \"\n",
        "    \"and tourist attractions. Your responsibility is to represent Madeira for interactions on the \"\n",
        "    \"website as faithfully as possible. Be professional and engaging, as if talking to a potential \"\n",
        "    \"client or future employer who came across the website. If you don't know the answer, say so.\\n\\n\"\n",
        ")\n",
        "system_prompt += f\"## Here is a PDF with information about Madeira:\\n{pdf_text}\\n\\n\"\n",
        "system_prompt += \"With this context, please chat with the user, always staying in character as a tourist guide in Madeira.\"\n",
        "system_prompt += \" Please, make sure to answer only with the information provided in the PDF. Also, please match the language of the user.\"\n"
      ],
      "id": "fc05bc62ff4bf63",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d40681ef418e3912"
      },
      "cell_type": "code",
      "source": [
        "# Define utility Functions\n",
        "\n",
        "def check_forecast(globalIdLocal, forecastDate):\n",
        "    \"\"\"\n",
        "    Gets the weather forecast for a specific location and date using IPMA API.\n",
        "    \"\"\"\n",
        "    url = f\"https://api.ipma.pt/open-data/forecast/meteorology/cities/daily/{globalIdLocal}.json\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        for day in data['data']:\n",
        "            if day['forecastDate'] == forecastDate:\n",
        "                return day\n",
        "    else:\n",
        "        print(f\"Error fetching forecast: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_date_formatted(forecastDate):\n",
        "    \"\"\"\n",
        "    Converts a natural language date into a formatted string (YYYY-MM-DD).\n",
        "    \"\"\"\n",
        "    parsed_date = dateparser.parse(forecastDate)\n",
        "    if not parsed_date:\n",
        "        return {\"error\": \"Could not parse the date. Try a format like 'tomorrow' or 'next Friday'.\"}\n",
        "    return parsed_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "\n",
        "def get_globalIdLocal():\n",
        "    \"\"\"\n",
        "    Returns the `globalIdLocal` for Funchal from the IPMA region list.\n",
        "    \"\"\"\n",
        "    url = \"https://api.ipma.pt/open-data/distrits-islands.json\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        for region in data['data']:\n",
        "            if region['local'] == 'Funchal':\n",
        "                return region['globalIdLocal']\n",
        "    else:\n",
        "        print(f\"Error fetching location ID: {response.status_code}\")\n",
        "        return None\n"
      ],
      "id": "d40681ef418e3912",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "360f2a36ae5c818d"
      },
      "cell_type": "code",
      "source": [
        "# Define the tool functions for structured use\n",
        "\n",
        "check_forecast_json = {\n",
        "    \"name\": \"check_forecast\",\n",
        "    \"description\": \"Gets the weather forecast for a given date.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"globalIdLocal\": {\n",
        "                \"type\": \"number\",\n",
        "                \"description\": \"The location ID to get the weather forecast for.\"\n",
        "            },\n",
        "            \"forecastDate\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Date of the forecast in 'YYYY-MM-DD' format.\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"globalIdLocal\", \"forecastDate\"],\n",
        "        \"additionalProperties\": False,\n",
        "    }\n",
        "}\n",
        "\n",
        "get_date_formatted_json = {\n",
        "    \"name\": \"get_date_formatted\",\n",
        "    \"description\": \"Parses a natural language date into a standard format.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"forecastDate\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Natural language input (e.g. 'next Friday').\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"forecastDate\"],\n",
        "        \"additionalProperties\": False,\n",
        "    }\n",
        "}\n",
        "\n",
        "get_global_id_json = {\n",
        "    \"name\": \"get_globalIdLocal\",\n",
        "    \"description\": \"Gets the globalIdLocal for Funchal, Madeira.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {},\n",
        "        \"required\": [],\n",
        "        \"additionalProperties\": False,\n",
        "    }\n",
        "}"
      ],
      "id": "360f2a36ae5c818d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "70db9ba2a8ad91a8"
      },
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\"type\": \"function\", \"function\": check_forecast_json},\n",
        "    {\"type\": \"function\", \"function\": get_global_id_json},\n",
        "    {\"type\": \"function\", \"function\": get_date_formatted_json}\n",
        "]"
      ],
      "id": "70db9ba2a8ad91a8",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "3c8050898d73d6ba"
      },
      "cell_type": "code",
      "source": [
        "# Tool execution Engine\n",
        "\n",
        "def handle_tool_calls(tool_calls):\n",
        "    \"\"\"\n",
        "    Executes tools requested by the AI and returns results.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for tool_call in tool_calls:\n",
        "        tool_name = tool_call.function.name\n",
        "        arguments = json.loads(tool_call.function.arguments)\n",
        "        print(f\"Tool called: {tool_name}\", flush=True)\n",
        "\n",
        "        if tool_name == \"check_forecast\":\n",
        "            result = check_forecast(**arguments)\n",
        "        elif tool_name == \"get_date_formatted\":\n",
        "            result = get_date_formatted(**arguments)\n",
        "        elif tool_name == \"get_globalIdLocal\":\n",
        "            result = get_globalIdLocal()\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown tool name: {tool_name}\")\n",
        "\n",
        "        results.append({\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": json.dumps(result),\n",
        "            \"tool_call_id\": tool_call.id\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "id": "3c8050898d73d6ba",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "5b0e3f9537b4f048"
      },
      "cell_type": "code",
      "source": [
        "# Chat function to be used with Gradio\n",
        "\n",
        "def chat(message, history):\n",
        "    \"\"\"\n",
        "    Manages the chat interaction and handles tool use if the model requests it.\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            tools=tools\n",
        "        )\n",
        "\n",
        "        finish_reason = response.choices[0].finish_reason\n",
        "\n",
        "        if finish_reason == \"tool_calls\":\n",
        "            message = response.choices[0].message\n",
        "            tool_calls = message.tool_calls\n",
        "            print(f\"Tool call detected: {tool_calls}\")\n",
        "            results = handle_tool_calls(tool_calls)\n",
        "            messages.append(message)\n",
        "            messages.extend(results)\n",
        "        else:\n",
        "            done = True\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "id": "5b0e3f9537b4f048",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "6fe0908d6093b6bb"
      },
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ],
      "id": "6fe0908d6093b6bb",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}