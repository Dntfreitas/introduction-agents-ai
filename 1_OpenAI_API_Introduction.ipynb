{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dntfreitas/introduction-agents-ai/blob/main/1_OpenAI_API_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dc525129e8beda5",
      "metadata": {
        "id": "7dc525129e8beda5"
      },
      "source": [
        "# OpenAI API Introduction\n",
        "\n",
        "This tutorial will guide you through using the OpenAI API, a powerful tool for accessing various AI models, including those for text generation, image creation, and more.\n",
        "\n",
        "**What is the OpenAI API?**\n",
        "\n",
        "The OpenAI API provides programmatic access to OpenAI's cutting-edge AI models. This means you can integrate AI capabilities directly into your own applications, websites, or workflows without needing to build and train these models yourself.\n",
        "\n",
        "**Why use the OpenAI API?**\n",
        "\n",
        "*   **Access to State-of-the-Art Models:** Utilize some of the most advanced AI models available, trained on massive datasets.\n",
        "*   **Flexibility and Customization:** Integrate AI into your specific needs and applications.\n",
        "*   **Scalability:** Easily scale your usage based on demand.\n",
        "*   **Variety of Models:** Explore models for different tasks, including:\n",
        "    *   **Language Models (like GPT series):** For text generation, summarization, translation, question answering, and more.\n",
        "    *   **Image Models (like DALL-E):** For generating images from text descriptions.\n",
        "    *   **Embeddings Models:** For converting text into numerical representations useful for tasks like search and clustering.\n",
        "    *   **Speech-to-Text (Whisper):** For transcribing audio into text.\n",
        "\n",
        "**Prerequisites:**\n",
        "\n",
        "Before you begin, you'll need:\n",
        "\n",
        "*   An OpenAI account.\n",
        "*   An API key. You can obtain this from your OpenAI account settings. **Keep your API key secure and do not share it publicly.**\n",
        "*   Python installed on your system.\n",
        "*   The `openai` Python library installed.\n",
        "\n",
        "**Getting Started:**\n",
        "\n",
        "The basic workflow involves:\n",
        "\n",
        "1.  **Installing the `openai` library.**\n",
        "2.  **Setting up your API key.**\n",
        "3.  **Making requests to the API.**\n",
        "4.  **Processing the API responses.**\n",
        "\n",
        "This tutorial will cover these steps in detail, providing code examples in Python using Google Colab or Jupyter notebooks. We will start with the most commonly used feature: text generation with the GPT models.\n",
        "\n",
        "Let's begin by installing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "id": "57f1c43a6d36c043",
      "metadata": {
        "id": "57f1c43a6d36c043"
      },
      "source": [
        "# Let's make sure we have the required libraries installed for this tutorial.\n",
        "!pip install openai"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "68364e8635d35727",
      "metadata": {
        "id": "68364e8635d35727"
      },
      "source": [
        "# Now, let's import the necessary libraries and set up our environment.\n",
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "11AuC3k_cfBa",
      "metadata": {
        "id": "11AuC3k_cfBa"
      },
      "source": [
        "# As we are going to use Google Coolab, we don't need to load the environment variables.\n",
        "# Otherwise, you can use the following code to load the environment variables from a `.env` file.\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv(override=True)\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "ekH3ciFhceZY",
      "metadata": {
        "id": "ekH3ciFhceZY"
      },
      "source": [
        "# Now, let's initialize the OpenAI API client.\n",
        "openai = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "aeb876d231cd973e",
      "metadata": {
        "id": "aeb876d231cd973e"
      },
      "source": [
        "## Completion function\n",
        "\n",
        "The following function will be used to get the completion from the OpenAI API."
      ]
    },
    {
      "cell_type": "code",
      "id": "eca7b8e9f4f7e811",
      "metadata": {
        "id": "eca7b8e9f4f7e811"
      },
      "source": [
        "def get_completion(prompt, model=\"gpt-4.1-nano\", temperature=1, top_p=0.1):\n",
        "    \"\"\"\n",
        "    Get the completion from the OpenAI API\n",
        "    :param prompt: the prompt to send to the API\n",
        "    :param model: the model to use\n",
        "    :param temperature: the temperature to use\n",
        "    :param top_p: the top_p to use\n",
        "    :return: the completion\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "    )\n",
        "    completion = response.choices[0].message.content\n",
        "    return completion"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "OYUmEx9Cc8h5",
      "metadata": {
        "id": "OYUmEx9Cc8h5"
      },
      "source": [
        "display(Markdown(get_completion(\"Write a motivation to study Agentic AI\")))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "83b6e5eaf36e8518"
      },
      "cell_type": "markdown",
      "source": [
        "# Agentic AI\n",
        "\n",
        "Let's create our first Agentic AI example. The idea is to use the OpenAI API to generate a question about Agentic AI, and then use the answer to generate a new question. This is a simple example of how to use \"Agentic AI\" to generate ideas and a roadmap for using it in a specific area.\n",
        "\n",
        "This builds the foundation for a more complex Agentic AI system, where we can use the answer from the previous question to ask a new question."
      ],
      "id": "83b6e5eaf36e8518"
    },
    {
      "cell_type": "code",
      "id": "3f0f2175d3355b75",
      "metadata": {
        "id": "3f0f2175d3355b75"
      },
      "source": [
        "question = get_completion(\"Make me a question about Agentic AI\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "5f48b171cfe815d5",
      "metadata": {
        "id": "5f48b171cfe815d5"
      },
      "source": [
        "display(Markdown(get_completion(question)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "905aec31dc3e866d",
      "metadata": {
        "id": "905aec31dc3e866d"
      },
      "source": [
        "# Let's make a more complex example, with 3 \"agentic AI\" steps.\n",
        "area = get_completion(\"Tell me an area where Agentic AI can be used. Respond only with the area.\")\n",
        "ideas = get_completion(f\"Give me 3 ideas for using Agentic AI in {area}.\")\n",
        "roadmap = get_completion(f\"Make a roadmap for using Agentic AI in {area} with the following ideas: {ideas}\")\n",
        "\n",
        "display(Markdown(roadmap))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "2caa075a96530bd9",
      "metadata": {
        "id": "2caa075a96530bd9"
      },
      "source": [
        "The previous example is a simple example of how to \"Agentic AI\" can be used to generate ideas and a roadmap for using it in a specific area. The idea is to use the previous answer to ask a new question, and then use the answer to generate a new question. This is a simple example of how to use \"Agentic AI\" to generate ideas and a roadmap for using it in a specific area.\n",
        "\n",
        "This example can be extended, for example, considering other LLMs. Meaning that we can use the answer from the previous question to ask a new question to another LLM.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y6WPHR1mdfkY",
      "metadata": {
        "id": "Y6WPHR1mdfkY"
      },
      "source": [
        "# Roles\n",
        "\n",
        "The different roles typically used in interacting with OpenAI's chat-based models are:\n",
        "\n",
        "*   **`system`:** This role provides initial instructions or context to the model. It helps set the overall behavior, tone, or constraints for the conversation. Think of it as providing high-level guidance to the AI before the user even starts talking.\n",
        "*   **`user`:** This role represents the input from the human user. This is where you put the prompts, questions, or requests you want the AI to respond to.\n",
        "*   **`assistant`:** This role represents the responses from the AI model itself. In a conversation, the `assistant`'s messages are generated by the model based on the preceding `system` and `user` messages.\n",
        "\n",
        "In a typical interaction, you might start with an optional `system` message, followed by alternating `user` and `assistant` messages to build a conversational history. The `get_completion` function you have currently only uses the `user` role to send a single prompt. For more complex interactions or to maintain conversation history, you would build a list of messages with these different roles."
      ]
    },
    {
      "cell_type": "code",
      "id": "c7994362d80b09c6",
      "metadata": {
        "id": "c7994362d80b09c6"
      },
      "source": [
        "# Example of using roles\n",
        "system_message = {\"role\": \"system\", \"content\": \"You are a professor from the primary school. You are a specialist in Agentic AI.\"}\n",
        "user_message = {\"role\": \"user\", \"content\": \"What is the definition of Agentic AI?\"}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "df74905756738555"
      },
      "cell_type": "code",
      "source": [
        "# Now, let's create a list of messages to send to the OpenAI API. This will include the system message and the user message.\n",
        "messages = [\n",
        "    system_message,\n",
        "    user_message\n",
        "]\n",
        "\n",
        "# Now, let's use the `get_completion` function to get the response from the model.\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    messages=messages,\n",
        "    temperature=1.0,\n",
        "    top_p=0.1,\n",
        ")\n",
        "completion = response.choices[0].message.content\n",
        "display(Markdown(completion))"
      ],
      "id": "df74905756738555",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "workshop-agents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}